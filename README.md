# NasaSpaceApps2023 - Immersed in the Sounds of Space

Idea Approach: 

Innovations in data visualization continue to expand our understanding of complex information. One such groundbreaking technique harnesses generative AI and RGB color mapping to create a unique form of sonification, transforming videos into auditory experiences by mapping frequency to the Root Mean Square (RMS) value of brightness.

This sonification process begins with the input of a video, a rich source of visual data. Through the application of generative AI algorithms, the video is analyzed frame by frame, extracting the brightness information from each pixel. This step is crucial, as it provides the raw data for the subsequent mapping process.

Once the brightness data is extracted, the RMS value for each frame is calculated. RMS is a mathematical representation of the intensity of brightness, capturing both the magnitude and distribution of light within each frame. These RMS values serve as the foundation for generating sound.

In the next stage, RGB color mapping is applied to these RMS values. Each value is assigned a corresponding RGB color, where variations in brightness intensity are translated into shifts in color spectrum. This mapping technique ensures that the auditory experience is not only based on intensity but also color, enriching the sonification.

With the RMS values mapped to RGB colors, the generative AI algorithm transforms this data into sound. Frequency, often associated with pitch in auditory perception, is used to represent the RMS values and, by extension, the brightness of each frame. Higher RMS values produce higher frequencies, creating a dynamic soundscape that evolves in response to changes in brightness across the video.

The result is a fascinating fusion of sensory experiences. Viewers can now hear the video's content, with shifts in pitch and tone corresponding to fluctuations in brightness and color. This multi-modal approach to data interpretation opens up new opportunities for artistic expression, scientific analysis, and data communication. It allows us to explore and appreciate visual information through our sense of hearing, offering fresh perspectives and potentially revealing insights that might have gone unnoticed through traditional visualization methods. The combined power of generative AI, RGB color mapping, and sonification transforms videos into immersive and multi-dimensional experiences, enhancing our understanding and appreciation of complex visual data.

We also viewed the reulting generated sound in the form of a graph as follows: 
![spectogram1](https://github.com/vbafnaa/NasaSpaceApps2023/assets/102181892/d3ad53bc-1d64-4db3-8882-05ce44b1e068)
